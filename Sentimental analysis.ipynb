{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pscxceXrhi6V",
        "outputId": "3853d6bf-5519-4130-9ff0-f9a8b068b61a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "<ipython-input-3-0853718e5fb1>:22: DtypeWarning: Columns (1,2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  dataset = pd.read_csv(file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset columns: Index(['sl number', 'Title', 'Review_Text', 'Stars', 'Unnamed: 4',\n",
            "       'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9',\n",
            "       'Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12', 'Unnamed: 13',\n",
            "       'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17',\n",
            "       'Unnamed: 18', 'Unnamed: 19', 'Unnamed: 20', 'Unnamed: 21',\n",
            "       'Unnamed: 22'],\n",
            "      dtype='object')\n",
            "Sample Data:\n",
            "   sl number                   Title  \\\n",
            "0        0.0           david kinzett   \n",
            "1        1.0         Bradley Slining   \n",
            "2        2.0            Mr Mark Shaw   \n",
            "3        3.0  Benjamin F Johnson Jr.   \n",
            "4        4.0             Donna Light   \n",
            "\n",
            "                                         Review_Text  Stars  Unnamed: 4  \\\n",
            "0  I regularly use Amazon to order and deliver my...    5.0         NaN   \n",
            "1  This is like the third package in 2 months \"de...    2.0         NaN   \n",
            "2  This review did not directly affect me but my ...    1.0         NaN   \n",
            "3  As a Prime customer I am deeply disappointed. ...    3.0         NaN   \n",
            "4  Please explain why amazon says my new card num...    2.0         NaN   \n",
            "\n",
            "   Unnamed: 5  Unnamed: 6  Unnamed: 7  Unnamed: 8  Unnamed: 9  ...  \\\n",
            "0         NaN         NaN         NaN         NaN         NaN  ...   \n",
            "1         NaN         NaN         NaN         NaN         NaN  ...   \n",
            "2         NaN         NaN         NaN         NaN         NaN  ...   \n",
            "3         NaN         NaN         NaN         NaN         NaN  ...   \n",
            "4         NaN         NaN         NaN         NaN         NaN  ...   \n",
            "\n",
            "   Unnamed: 13  Unnamed: 14  Unnamed: 15  Unnamed: 16  Unnamed: 17  \\\n",
            "0          NaN          NaN          NaN          NaN          NaN   \n",
            "1          NaN          NaN          NaN          NaN          NaN   \n",
            "2          NaN          NaN          NaN          NaN          NaN   \n",
            "3          NaN          NaN          NaN          NaN          NaN   \n",
            "4          NaN          NaN          NaN          NaN          NaN   \n",
            "\n",
            "   Unnamed: 18  Unnamed: 19  Unnamed: 20  Unnamed: 21  Unnamed: 22  \n",
            "0          NaN          NaN          NaN          NaN          NaN  \n",
            "1          NaN          NaN          NaN          NaN          NaN  \n",
            "2          NaN          NaN          NaN          NaN          NaN  \n",
            "3          NaN          NaN          NaN          NaN          NaN  \n",
            "4          NaN          NaN          NaN          NaN          NaN  \n",
            "\n",
            "[5 rows x 23 columns]\n",
            "Sentiment Analysis Report:\n",
            "  Sentiment  Percentage\n",
            "0   Neutral   97.939365\n",
            "1  Positive    1.526528\n",
            "2  Negative    0.534107\n",
            "Sentiment summary saved to: /content/Sentiment_Summary_Report.csv\n",
            "Sentiment analysis results saved to: /content/Sentiment_Analysis_Results.csv\n",
            "Sample sentiment analysis results:\n",
            "                                         Review_Text  \\\n",
            "0  I regularly use Amazon to order and deliver my...   \n",
            "1  This is like the third package in 2 months \"de...   \n",
            "2  This review did not directly affect me but my ...   \n",
            "3  As a Prime customer I am deeply disappointed. ...   \n",
            "4  Please explain why amazon says my new card num...   \n",
            "\n",
            "                                    Processed_Review Sentiment  \n",
            "0  regularli use amazon order deliv product alway...  Positive  \n",
            "1  like third packag 2 month deliv realli anyon k...  Negative  \n",
            "2  review directli affect neighbour deliveri driv...  Positive  \n",
            "3  prime custom deepli disappoint tell overnight ...  Positive  \n",
            "4  pleas explain amazon say new card number inval...  Positive  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "import nltk\n",
        "from textblob import TextBlob\n",
        "\n",
        "# Download necessary NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Initialize NLP tools\n",
        "tokenizer = TreebankWordTokenizer()\n",
        "stop_words = stopwords.words(\"english\")\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/Cleaned_Combined_Reviews (1).csv'\n",
        "dataset = pd.read_csv(file_path)\n",
        "\n",
        "# Inspect the dataset\n",
        "print(\"Dataset columns:\", dataset.columns)\n",
        "print(\"Sample Data:\")\n",
        "print(dataset.head())\n",
        "\n",
        "# Assuming the review text is in a column named 'Review_Text'\n",
        "review_column = 'Review_Text'  # Replace with the correct column name if different\n",
        "\n",
        "# Check if the review column exists\n",
        "if review_column not in dataset.columns:\n",
        "    raise ValueError(f\"Column '{review_column}' not found in the dataset.\")\n",
        "\n",
        "# Handle missing or non-string values in the review column\n",
        "dataset[review_column] = dataset[review_column].fillna(\"\").astype(str)\n",
        "\n",
        "# Function to preprocess text\n",
        "def preprocess_text(text):\n",
        "    # Convert text to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove special characters\n",
        "    text = re.sub('[^a-z0-9]', ' ', text)\n",
        "    # Tokenize the text\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    # Remove stopwords\n",
        "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "    # Lemmatize tokens\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
        "    # Stem tokens\n",
        "    stemmed_tokens = [stemmer.stem(word) for word in lemmatized_tokens]\n",
        "    # Join tokens back into a single string\n",
        "    return \" \".join(stemmed_tokens)\n",
        "\n",
        "# Apply preprocessing\n",
        "dataset['Processed_Review'] = dataset[review_column].apply(preprocess_text)\n",
        "\n",
        "# Function for sentiment analysis\n",
        "def analyze_sentiment(review):\n",
        "    analysis = TextBlob(review)\n",
        "    polarity = analysis.sentiment.polarity\n",
        "    if polarity > 0:\n",
        "        return \"Positive\"\n",
        "    elif polarity < 0:\n",
        "        return \"Negative\"\n",
        "    else:\n",
        "        return \"Neutral\"\n",
        "\n",
        "# Perform sentiment analysis\n",
        "dataset['Sentiment'] = dataset['Processed_Review'].apply(analyze_sentiment)\n",
        "\n",
        "# Calculate sentiment percentages\n",
        "sentiment_counts = dataset['Sentiment'].value_counts(normalize=True) * 100\n",
        "sentiment_summary = sentiment_counts.reset_index()\n",
        "sentiment_summary.columns = ['Sentiment', 'Percentage']\n",
        "\n",
        "# Print sentiment summary to the console\n",
        "print(\"Sentiment Analysis Report:\")\n",
        "print(sentiment_summary)\n",
        "\n",
        "# Save sentiment percentages to a CSV file for further use\n",
        "sentiment_summary.to_csv('/content/Sentiment_Summary_Report.csv', index=False)\n",
        "print(\"Sentiment summary saved to: /content/Sentiment_Summary_Report.csv\")\n",
        "\n",
        "# Save results for future use\n",
        "output_file_path = '/content/Sentiment_Analysis_Results.csv'\n",
        "dataset.to_csv(output_file_path, index=False)\n",
        "print(f\"Sentiment analysis results saved to: {output_file_path}\")\n",
        "\n",
        "# Display sample results\n",
        "print(\"Sample sentiment analysis results:\")\n",
        "print(dataset[[review_column, 'Processed_Review', 'Sentiment']].head())\n"
      ]
    }
  ]
}